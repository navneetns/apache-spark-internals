<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Untitled :: The Internals Of Apache Spark</title>
    <link rel="canonical" href="http://books.japila.pl/apache-spark-internals/apache-spark-internals/2.4.4/spark-on-yarn/spark-yarn-applicationmaster.html">
    <meta name="generator" content="Antora 2.2.0">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-86782445-1"></script>
    <script>function gtag(){dataLayer.push(arguments)};window.dataLayer=window.dataLayer||[];gtag('js',new Date());gtag('config','UA-86782445-1')</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="http://books.japila.pl/apache-spark-internals">The Internals Of Apache Spark</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="#">Home</a>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Products</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Product A</a>
            <a class="navbar-item" href="#">Product B</a>
            <a class="navbar-item" href="#">Product C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Services</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Service A</a>
            <a class="navbar-item" href="#">Service B</a>
            <a class="navbar-item" href="#">Service C</a>
          </div>
        </div>
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link" href="#">Resources</a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="#">Resource A</a>
            <a class="navbar-item" href="#">Resource B</a>
            <a class="navbar-item" href="#">Resource C</a>
          </div>
        </div>
        <div class="navbar-item">
          <span class="control">
            <a class="button is-primary" href="#">Download</a>
          </span>
        </div>
      </div>
    </div>
  </nav>
</header>
<div class="body">
<div class="nav-container" data-component="apache-spark-internals" data-version="2.4.4">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Apache Spark</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-overview.html">Overview</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Job Commit Protocol</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-internal-io-FileCommitProtocol.html">FileCommitProtocol</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-internal-io-HadoopMapReduceCommitProtocol.html">HadoopMapReduceCommitProtocol</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-internal-io-HadoopMapRedCommitProtocol.html">HadoopMapRedCommitProtocol</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-internal-io-SparkHadoopWriter.html">SparkHadoopWriter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-internal-io-HadoopWriteConfigUtil.html">HadoopWriteConfigUtil</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-internal-io-HadoopMapReduceWriteConfigUtil.html">HadoopMapReduceWriteConfigUtil</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-internal-io-HadoopMapRedWriteConfigUtil.html">HadoopMapRedWriteConfigUtil</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Block Storage System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-BlockDataManager.html">BlockDataManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-BlockId.html">BlockId</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-ManagedBuffer.html">ManagedBuffer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-BlockManager.html">BlockManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-MemoryStore.html">MemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-BlockEvictionHandler.html">BlockEvictionHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-StorageMemoryPool.html">StorageMemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-MemoryPool.html">MemoryPool</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-DiskStore.html">DiskStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-RpcHandler.html">RpcHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-RpcResponseCallback.html">RpcResponseCallback</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-TransportRequestHandler.html">TransportRequestHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-TransportContext.html">TransportContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-TransportServer.html">TransportServer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-TransportClientFactory.html">TransportClientFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-MessageHandler.html">MessageHandler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-BlockManagerMaster.html">BlockManagerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-blockmanager-BlockManagerMasterEndpoint.html">BlockManagerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-DiskBlockManager.html">DiskBlockManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-BlockInfoManager.html">BlockInfoManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-BlockInfo.html">BlockInfo</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-blockmanager-BlockManagerSlaveEndpoint.html">BlockManagerSlaveEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-blockmanager-DiskBlockObjectWriter.html">DiskBlockObjectWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-BlockManager-BlockManagerSource.html">BlockManagerSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-BlockManager-ShuffleMetricsSource.html">ShuffleMetricsSource</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-blockmanager-StorageStatus.html">StorageStatus</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Transferring Data Blocks (between Nodes in Spark Application)</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-ShuffleClient.html">ShuffleClient</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-BlockTransferService.html">BlockTransferService</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-ShuffleClient-ExternalShuffleClient.html">ExternalShuffleClient</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-NettyBlockTransferService.html">NettyBlockTransferService</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-NettyBlockRpcServer.html">NettyBlockRpcServer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-BlockFetchingListener.html">BlockFetchingListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-RetryingBlockFetcher.html">RetryingBlockFetcher</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-RetryingBlockFetcher-BlockFetchStarter.html">BlockFetchStarter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shuffle System</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-shuffle-ShuffleManager.html">ShuffleManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-shuffle-ShuffleBlockResolver.html">ShuffleBlockResolver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-shuffle-SortShuffleManager.html">SortShuffleManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-IndexShuffleBlockResolver.html">IndexShuffleBlockResolver</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-shuffle-ShuffleHandle.html">ShuffleHandle</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-BaseShuffleHandle.html">BaseShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-BypassMergeSortShuffleHandle.html">BypassMergeSortShuffleHandle</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-SerializedShuffleHandle.html">SerializedShuffleHandle</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-shuffle-ShuffleWriter.html">ShuffleWriter</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-BypassMergeSortShuffleWriter.html">BypassMergeSortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-SortShuffleWriter.html">SortShuffleWriter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-UnsafeShuffleWriter.html">UnsafeShuffleWriter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-shuffle-ShuffleReader.html">ShuffleReader</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-shuffle-BlockStoreShuffleReader.html">BlockStoreShuffleReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-shuffle-ShuffleExternalSorter.html">ShuffleExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-shuffle-ShuffleInMemorySorter.html">ShuffleInMemorySorter</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-architecture.html">Spark Architecture</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-driver.html">Driver</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-Executor.html">Executor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-Executor-TaskRunner.html">TaskRunner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-executor-ExecutorSource.html">ExecutorSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-master.html">Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-workers.html">Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-SparkConf.html">SparkConf</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-properties.html">Spark Properties and spark-defaults.conf Properties File</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-deploy-mode.html">Deploy Mode</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-SparkContext.html">SparkContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-HeartbeatReceiver.html">HeartbeatReceiver RPC Endpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkContext-creating-instance-internals.html">Inside Creating SparkContext</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-sparkcontext-ConsoleProgressBar.html">ConsoleProgressBar</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-sparkcontext-SparkStatusTracker.html">SparkStatusTracker</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-sparkcontext-local-properties.html">Local Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-execution-model.html">Execution Model</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-configuration-properties.html">Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-anatomy-spark-application.html">Anatomy of Spark Application</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd.html">RDD</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-rdd-RDD.html">RDD API</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-operations.html">Operators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-transformations.html">Transformations</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-rdd-PairRDDFunctions.html">PairRDDFunctions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-actions.html">Actions</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-rdd-lineage.html">RDD Lineage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-caching.html">Caching and Persistence</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-StorageLevel.html">StorageLevel</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-checkpointing.html">Checkpointing</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-CheckpointRDD.html">CheckpointRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-partitions.html">Partitions and Partitioning</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-Partition.html">Partition</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-Partitioner.html">Partitioner</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-HashPartitioner.html">HashPartitioner</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-rdd-shuffle.html">Shuffling</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rdd-Dependency.html">RDD Dependencies</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-NarrowDependency.html">NarrowDependency</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-ShuffleDependency.html">ShuffleDependency</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-Aggregator.html">Map/Reduce-side Aggregator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Specialized RDDs</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-ParallelCollectionRDD.html">ParallelCollectionRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-MapPartitionsRDD.html">MapPartitionsRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-OrderedRDDFunctions.html">OrderedRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-CoGroupedRDD.html">CoGroupedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-SubtractedRDD.html">SubtractedRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-HadoopRDD.html">HadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-NewHadoopRDD.html">NewHadoopRDD</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rdd-ShuffledRDD.html">ShuffledRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-TaskLocation.html">TaskLocation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-core-AppStatusStore.html">AppStatusStore</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-core-AppStatusPlugin.html">AppStatusPlugin</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-core-KVStore.html">KVStore</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-core-KVStoreView.html">KVStoreView</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-core-ElementTrackingStore.html">ElementTrackingStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-core-InMemoryStore.html">InMemoryStore</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-core-LevelDB.html">LevelDB</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-InterruptibleIterator.html">InterruptibleIterator</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-barrier-execution-mode.html">Barrier Execution Mode</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-RDDBarrier.html">RDDBarrier</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Shared Variables</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-broadcast.html">Broadcast variables</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-accumulators.html">Accumulators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-AccumulatorContext.html">AccumulatorContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Tools</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-shell.html">Spark Shell (spark-shell)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-submit.html">Spark Submit (spark-submit)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-submit-SparkSubmitArguments.html">SparkSubmitArguments</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-submit-SparkSubmitOptionParser.html">SparkSubmitOptionParser</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-submit-SparkSubmitCommandBuilder.html">SparkSubmitCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-class.html">spark-class shell script</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-AbstractCommandBuilder.html">AbstractCommandBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-SparkLauncher.html">SparkLauncher</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Core Services</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Low-Level Spark Task Scheduler</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-ActiveJob.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-SchedulableBuilder.html">SchedulableBuilder</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-FIFOSchedulableBuilder.html">FIFOSchedulableBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-FairSchedulableBuilder.html">FairSchedulableBuilder</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-TaskScheduler.html">TaskScheduler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-TaskSchedulerImpl.html">TaskSchedulerImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-Task.html">Task</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-ShuffleMapTask.html">ShuffleMapTask</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-ResultTask.html">ResultTask</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskSet.html">TaskSet</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskSetManager.html">TaskSetManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-Schedulable.html">Schedulable Entities</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-Pool.html">Schedulable Pool</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-SchedulingMode.html">Scheduling Mode</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskInfo.html">TaskInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-TaskRunner-FetchFailedException.html">FetchFailedException</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-MapStatus.html">MapStatus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskDescription.html">TaskDescription</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-taskschedulerimpl-speculative-execution.html">Speculative Execution of Tasks</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskResultGetter.html">TaskResultGetter</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-TaskContext.html">TaskContext</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-BarrierTaskContext.html">BarrierTaskContext</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-TaskContextImpl.html">TaskContextImpl</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskResult.html">TaskResults</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-TaskSetBlacklist.html">TaskSetBlacklist</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">High-Level Spark Stage Scheduler</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-DAGScheduler.html">DAGScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-Stage.html">Stage</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-ShuffleMapStage.html">ShuffleMapStage</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-ResultStage.html">ResultStage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-StageInfo.html">StageInfo</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-scheduler-DAGSchedulerEventProcessLoop.html">DAGScheduler Event Bus</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-JobListener.html">JobListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-scheduler-JobWaiter.html">JobWaiter</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-memory-unified-memory-management.html">Unified Memory Management</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-memory-TaskMemoryManager.html">TaskMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-memory-MemoryConsumer.html">MemoryConsumer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-MemoryManager.html">MemoryManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-UnifiedMemoryManager.html">UnifiedMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-StaticMemoryManager.html">StaticMemoryManager</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-MemoryManager-properties.html">MemoryManager Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-SerializerManager.html">SerializerManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-SparkEnv.html">SparkEnv</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-SchedulerBackend.html">SchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-CoarseGrainedSchedulerBackend.html">CoarseGrainedSchedulerBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-CoarseGrainedSchedulerBackend-DriverEndpoint.html">DriverEndpoint</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-ExecutorBackend.html">ExecutorBackend</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-CoarseGrainedExecutorBackend.html">CoarseGrainedExecutorBackend</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-ExternalShuffleService.html">ExternalShuffleService</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-OneForOneStreamManager.html">OneForOneStreamManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-ShuffleBlockFetcherIterator.html">ShuffleBlockFetcherIterator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-ExternalSorter.html">ExternalSorter</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-service-mapoutputtracker.html">MapOutputTracker</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-service-MapOutputTrackerMaster.html">MapOutputTrackerMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-service-MapOutputTrackerMasterEndpoint.html">MapOutputTrackerMasterEndpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-service-MapOutputTrackerWorker.html">MapOutputTrackerWorker</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-serialization.html">Serialization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-Serializer.html">Serializer</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SerializerInstance.html">SerializerInstance</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SerializationStream.html">SerializationStream</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-DeserializationStream.html">DeserializationStream</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-ExternalClusterManager.html">ExternalClusterManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-service-broadcastmanager.html">BroadcastManager</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-BroadcastFactory.html">BroadcastFactory</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-TorrentBroadcastFactory.html">TorrentBroadcastFactory</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-TorrentBroadcast.html">TorrentBroadcast</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-CompressionCodec.html">CompressionCodec</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-service-contextcleaner.html">ContextCleaner</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-CleanerListener.html">CleanerListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-dynamic-allocation.html">Dynamic Allocation (of Executors)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-ExecutorAllocationManager.html">ExecutorAllocationManager</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-service-ExecutorAllocationClient.html">ExecutorAllocationClient</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-service-ExecutorAllocationManagerSource.html">ExecutorAllocationManagerSource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-http-file-server.html">HTTP File Server</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-data-locality.html">Data Locality</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-cachemanager.html">Cache Manager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-service-outputcommitcoordinator.html">OutputCommitCoordinator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-rpc.html">RPC Environment</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rpc-RpcEnv.html">RpcEnv</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rpc-RpcEndpoint.html">RpcEndpoint</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-RpcEndpointRef.html">RpcEndpointRef</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-RpcEnvFactory.html">RpcEnvFactory</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-rpc-netty.html">Netty-based RpcEnv</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-TransportConf.html">TransportConf</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-Utils.html">Utils Helper Object</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Security</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-webui-security.html">Securing Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-deployment-environments.html">Deployment Environments</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-cluster.html">Spark on cluster</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-history-server.html">Spark History Server</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-HistoryServer.html">HistoryServer</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-SQLHistoryListener.html">SQLHistoryListener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-FsHistoryProvider.html">FsHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-ApplicationHistoryProvider.html">ApplicationHistoryProvider</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-HistoryServerArguments.html">HistoryServerArguments</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-ApplicationCacheOperations.html">ApplicationCacheOperations</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-history-server-ApplicationCache.html">ApplicationCache</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Monitoring, Tuning, Debugging and Testing</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-logging.html">Logging</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-tuning.html">Performance Tuning</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-scheduler-SparkListener.html">SparkListener</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListener-AppStatusListener.html">AppStatusListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListener-EventLoggingListener.html">EventLoggingListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListener-ExecutorAllocationListener.html">ExecutorAllocationListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListener-SpillListener.html">SpillListener</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListener-StatsReportListener.html">StatsReportListener</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-scheduler-LiveListenerBus.html">LiveListenerBus</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-SparkListenerBus.html">SparkListenerBus</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListenerBus-AsyncEventQueue.html">AsyncEventQueue</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkListenerBus-ReplayListenerBus.html">ReplayListenerBus</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-JsonProtocol.html">JsonProtocol</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-debugging.html">Debugging Spark</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Varia</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../varia/spark-building-from-sources.html">Building Apache Spark from Sources</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../varia/spark-hadoop.html">Spark and Hadoop</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-SparkHadoopUtil.html">SparkHadoopUtil</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../varia/spark-inmemory-filesystems.html">Spark and software in-memory file systems</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../varia/spark-others.html">Spark and The Others</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../varia/spark-deeplearning.html">Distributed Deep Learning on Spark</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../varia/spark-packages.html">Spark Packages</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-tips-and-tricks.html">Spark Tips and Tricks</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-tips-and-tricks-access-private-members-spark-shell.html">Access private members in Scala in Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-tips-and-tricks-sparkexception-task-not-serializable.html">SparkException: Task not serializable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-tips-and-tricks-running-spark-windows.html">Running Spark Applications on Windows</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Further Learning</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-courses.html">Courses</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-books.html">Books</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-sql.html">Spark SQL</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../spark-structured-streaming.html">Spark Structured Streaming</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/index.html">Web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-jobs.html">Jobs</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-stages.html">Stages</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-storage.html">Storage</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-environment.html">Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-executors.html">Executors</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-JobsTab.html">JobsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-AllJobsPage.html">AllJobsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-JobPage.html">JobPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-StagesTab.html">StagesTab&#8201;&#8212;&#8201;Stages for All Jobs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-AllStagesPage.html">AllStagesPage&#8201;&#8212;&#8201;Stages for All Jobs</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-StagePage.html">StagePage&#8201;&#8212;&#8201;Stage Details</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-PoolPage.html">PoolPage&#8201;&#8212;&#8201;Pool Details</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-StorageTab.html">StorageTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-StoragePage.html">StoragePage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-RDDPage.html">RDDPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-EnvironmentTab.html">EnvironmentTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-EnvironmentPage.html">EnvironmentPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-ExecutorsTab.html">ExecutorsTab</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-ExecutorsPage.html">ExecutorsPage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-ExecutorThreadDumpPage.html">ExecutorThreadDumpPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-SparkUI.html">SparkUI&#8201;&#8212;&#8201;Web UI of Spark Application</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-SparkUITab.html">SparkUITab</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-BlockStatusListener.html">BlockStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-EnvironmentListener.html">EnvironmentListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-executors-ExecutorsListener.html">ExecutorsListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-JobProgressListener.html">JobProgressListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-StorageStatusListener.html">StorageStatusListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-StorageListener.html">StorageListener&#8201;&#8212;&#8201;Spark Listener for Tracking Persistence Status of RDD Blocks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-RDDOperationGraphListener.html">RDDOperationGraphListener Spark Listener</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-webui-WebUI.html">WebUI&#8201;&#8212;&#8201;Framework For Web UIs</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-WebUIPage.html">WebUIPage&#8201;&#8212;&#8201;Contract of Pages in Web UI</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-webui-WebUITab.html">WebUITab&#8201;&#8212;&#8201;Contract of Tabs in Web UI</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-RDDStorageInfo.html">RDDStorageInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-core-RDDInfo.html">RDDInfo</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../webui/spark-core-LiveEntity.html">LiveEntity</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../webui/spark-core-LiveRDD.html">LiveRDD</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-UIUtils.html">UIUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-JettyUtils.html">JettyUtils</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../webui/spark-webui-properties.html">web UI Configuration Properties</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../metrics/index.html">Spark Metrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../metrics/spark-metrics-MetricsSystem.html">MetricsSystem</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../metrics/spark-metrics-MetricsConfig.html">MetricsConfig</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../metrics/spark-metrics-Source.html">Source</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../metrics/spark-scheduler-DAGSchedulerSource.html">DAGSchedulerSourcer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../metrics/spark-metrics-Sink.html">Sink</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../metrics/spark-metrics-MetricsServlet.html">MetricsServlet JSON Metrics Sink</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../metrics/spark-metrics-properties.html">Metrics Configuration Properties</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../metrics/spark-executor-TaskMetrics.html">TaskMetrics</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../metrics/spark-executor-ShuffleWriteMetrics.html">ShuffleWriteMetrics</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/index.html">Spark MLlib</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-pipelines.html">ML Pipelines (spark.ml)</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-Pipeline.html">Pipeline</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-PipelineStage.html">PipelineStage</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-transformers.html">Transformers</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-Transformer.html">Transformer</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-transformers-Tokenizer.html">Tokenizer</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-estimators.html">Estimators</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Estimator.html">Estimator</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-StringIndexer.html">StringIndexer</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-KMeans.html">KMeans</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-TrainValidationSplit.html">TrainValidationSplit</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Predictor.html">Predictor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-RandomForestRegressor.html">RandomForestRegressor</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Regressor.html">Regressor</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-LinearRegression.html">LinearRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="4">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Classifier.html">Classifier</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-RandomForestClassifier.html">RandomForestClassifier</a>
  </li>
  <li class="nav-item" data-depth="5">
    <a class="nav-link" href="../spark-mllib/spark-mllib-DecisionTreeClassifier.html">DecisionTreeClassifier</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-models.html">Models</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-Model.html">Model</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Evaluator.html">Evaluator&#8201;&#8212;&#8201;ML Pipeline Component for Model Scoring</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-BinaryClassificationEvaluator.html">BinaryClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Binary Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ClusteringEvaluator.html">ClusteringEvaluator&#8201;&#8212;&#8201;Evaluator of Clustering Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-MulticlassClassificationEvaluator.html">MulticlassClassificationEvaluator&#8201;&#8212;&#8201;Evaluator of Multiclass Classification Models</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-RegressionEvaluator.html">RegressionEvaluator&#8201;&#8212;&#8201;Evaluator of Regression Models</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-CrossValidator.html">CrossValidator&#8201;&#8212;&#8201;Model Tuning / Finding The Best Model</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-CrossValidatorModel.html">CrossValidatorModel</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ParamGridBuilder.html">ParamGridBuilder</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-CrossValidator-example.html">CrossValidator with Pipeline Example</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-Params.html">Params and ParamMaps</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ValidatorParams.html">ValidatorParams</a>
  </li>
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../spark-mllib/spark-mllib-HasParallelism.html">HasParallelism</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-pipelines-persistence.html">ML Persistence&#8201;&#8212;&#8201;Saving and Loading Models and Pipelines</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-MLWritable.html">MLWritable</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-MLReader.html">MLReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-pipelines-example-classification.html">Example&#8201;&#8212;&#8201;Text Classification</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-pipelines-example-regression.html">Example&#8201;&#8212;&#8201;Linear Regression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-logistic-regression.html">Logistic Regression</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-LogisticRegression.html">LogisticRegression</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-latent-dirichlet-allocation.html">Latent Dirichlet Allocation (LDA)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-vector.html">Vector</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-labeledpoint.html">LabeledPoint</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-streaming.html">Streaming MLlib</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-GeneralizedLinearRegression.html">GeneralizedLinearRegression</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-mllib/spark-mllib-alternating-least-squares.html">Alternating Least Squares (ALS) Matrix Factorization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ALS.html">ALS&#8201;&#8212;&#8201;Estimator for ALSModel</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ALSModel.html">ALSModel&#8201;&#8212;&#8201;Model for Predictions</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-mllib/spark-mllib-ALSModelReader.html">ALSModelReader</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-Instrumentation.html">Instrumentation</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-mllib/spark-mllib-MLUtils.html">MLUtils</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-local/index.html">Spark local</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-local/spark-LocalSchedulerBackend.html">LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-local/spark-LocalEndpoint.html">LocalEndpoint&#8201;&#8212;&#8201;RPC Endpoint for LocalSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-local/spark-LauncherBackend.html">LauncherBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Spark on YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-YarnShuffleService.html">YarnShuffleService&#8201;&#8212;&#8201;ExternalShuffleService on YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-ExecutorRunnable.html">ExecutorRunnable</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-client.html">Client</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-yarnrmclient.html">YarnRMClient</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-yarn-applicationmaster.html">ApplicationMaster</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-AMEndpoint.html">AMEndpoint&#8201;&#8212;&#8201;ApplicationMaster RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-YarnClusterManager.html">YarnClusterManager&#8201;&#8212;&#8201;ExternalClusterManager for YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-yarn-taskschedulers.html">TaskSchedulers for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-yarnscheduler.html">YarnScheduler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-yarnclusterscheduler.html">YarnClusterScheduler</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-yarn-schedulerbackends.html">SchedulerBackends for YARN</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-yarnschedulerbackend.html">YarnSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-client-yarnclientschedulerbackend.html">YarnClientSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-cluster-yarnclusterschedulerbackend.html">YarnClusterSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-cluster-YarnSchedulerEndpoint.html">YarnSchedulerEndpoint RPC Endpoint</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-YarnAllocator.html">YarnAllocator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-introduction.html">Introduction to Hadoop YARN</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-cluster-setup.html">Setting up YARN Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="spark-yarn-kerberos.html">Kerberos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="spark-yarn-ConfigurableCredentialManager.html">ConfigurableCredentialManager</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-ClientDistributedCacheManager.html">ClientDistributedCacheManager</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-YarnSparkHadoopUtil.html">YarnSparkHadoopUtil</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="spark-yarn-settings.html">Settings</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-standalone/index.html">Spark Standalone</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-Master.html">Standalone Master&#8201;&#8212;&#8201;Cluster Manager of Spark Standalone</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-worker.html">Standalone Worker</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-standalone/spark-standalone-webui.html">web UI</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../spark-standalone/spark-standalone-webui-ApplicationPage.html">ApplicationPage</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-LocalSparkCluster.html">LocalSparkCluster&#8201;&#8212;&#8201;Single-JVM Spark Standalone Cluster</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-submission-gateways.html">Submission Gateways</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-master-scripts.html">Management Scripts for Standalone Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-worker-scripts.html">Management Scripts for Standalone Workers</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-status.html">Checking Status</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-example-2-workers-on-1-node-cluster.html">Example 2-workers-on-1-node Standalone Cluster (one executor per worker)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-standalone/spark-standalone-StandaloneSchedulerBackend.html">StandaloneSchedulerBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rest-api/index.html">Status REST API</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rest-api/spark-api-ApiRootResource.html">ApiRootResource&#8201;&#8212;&#8201;/api/v1 URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../rest-api/spark-api-ApplicationListResource.html">ApplicationListResource&#8201;&#8212;&#8201;applications URI Handler</a>
  </li>
  <li class="nav-item" data-depth="3">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rest-api/spark-api-OneApplicationResource.html">OneApplicationResource&#8201;&#8212;&#8201;applications/appId URI Handler</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="4">
    <a class="nav-link" href="../rest-api/spark-api-StagesResource.html">StagesResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../rest-api/spark-api-OneApplicationAttemptResource.html">OneApplicationAttemptResource</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rest-api/spark-api-AbstractApplicationResource.html">AbstractApplicationResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rest-api/spark-api-BaseAppResource.html">BaseAppResource</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../rest-api/spark-api-ApiRequestContext.html">ApiRequestContext</a>
  </li>
  <li class="nav-item" data-depth="2">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../rest-api/spark-api-UIRoot.html">UIRoot&#8201;&#8212;&#8201;Contract for Root Contrainers of Application UI Information</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="3">
    <a class="nav-link" href="../rest-api/spark-api-UIRootFromServletContext.html">UIRootFromServletContext</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../spark-on-mesos/index.html">Spark on Mesos</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-on-mesos/spark-mesos-MesosCoarseGrainedSchedulerBackend.html">MesosCoarseGrainedSchedulerBackend</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-on-mesos/spark-mesos-introduction.html">About Mesos</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../spark-on-mesos/spark-executor-backends-MesosExecutorBackend.html">MesosExecutorBackend</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <span class="nav-text">Exercises</span>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-pairrddfunctions-oneliners.html">One-liners using PairRDDFunctions</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-take-multiple-jobs.html">Learning Jobs and Partitions Using take Action</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-standalone-master-ha.html">Spark Standalone - Using ZooKeeper for High-Availability of Master</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-hello-world-using-spark-shell.html">Spark&#8217;s Hello World using Spark shell and Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-examples-wordcount-spark-shell.html">WordCount using Spark shell</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-first-app.html">Your first complete Spark application (using Scala and sbt)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-notable-use-cases.html">Spark (notable) use cases</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-sql-hive-orc-example.html">Using Spark SQL to update data in Hive using ORC files</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-custom-scheduler-listener.html">Developing Custom SparkListener to monitor DAGScheduler in Scala</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-custom-rpc-environment.html">Developing RPC Environment</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-custom-rdd.html">Developing Custom RDD</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-dataframe-jdbc-postgresql.html">Working with Datasets from JDBC Data Sources (and PostgreSQL)</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../exercises/spark-exercise-failing-stage.html">Causing Stage to Fail</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Apache Spark</span>
    <span class="version">2.4.4</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <span class="title">Apache Spark</span>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">2.4.4</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main>
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Apache Spark</a></li>
    <li><a href="index.html">Spark on YARN</a></li>
    <li><a href="spark-yarn-applicationmaster.html">ApplicationMaster</a></li>
  </ul>
</nav>
  <div class="edit-this-page"><a href="file:///antora/modules/spark-on-yarn/pages/spark-yarn-applicationmaster.adoc">Edit this Page</a></div>
</div>
<article class="doc">
<div class="sect1">
<h2 id="applicationmaster-aka-executorlauncher"><a class="anchor" href="#applicationmaster-aka-executorlauncher"></a><a class="link" href="#applicationmaster-aka-executorlauncher"><a id="ApplicationMaster"></a> ApplicationMaster (aka ExecutorLauncher)</a></h2>
<div class="sectionbody">
<div class="paragraph">
<p><code>ApplicationMaster</code> is the <a href="spark-yarn-introduction.adoc#ApplicationMaster">YARN ApplicationMaster</a> for a Spark application submitted to a YARN cluster (which is commonly called <a href="README.adoc">Spark on YARN</a>).</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-yarn-ApplicationMaster.png" alt="spark yarn ApplicationMaster">
</div>
<div class="title">Figure 1. ApplicationMaster&#8217;s Dependencies</div>
</div>
<div class="paragraph">
<p><code>ApplicationMaster</code> is a <a href="#main">standalone application</a> that <a href="spark-yarn-introduction.adoc#NodeManager">YARN NodeManager</a> runs in a YARN container to manage a Spark application running in a YARN cluster.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>From the official documentation of <a href="http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/YARN.html">Apache Hadoop YARN</a> (with some minor changes of mine):</p>
</div>
<div class="quoteblock">
<blockquote>
<div class="paragraph">
<p>The per-application ApplicationMaster is actually a framework-specific library and is tasked with negotiating cluster resources from the YARN ResourceManager and working with the YARN NodeManager(s) to execute and monitor the tasks.</p>
</div>
</blockquote>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>ApplicationMaster</code> (and <code>ExecutorLauncher</code>) is launched as a result of <a href="spark-yarn-client.adoc#createContainerLaunchContext"><code>Client</code> creating a <code>ContainerLaunchContext</code></a> to launch a Spark application on YARN.</p>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-yarn-ApplicationMaster-main.png" alt="spark yarn ApplicationMaster main">
</div>
<div class="title">Figure 2. Launching ApplicationMaster</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/ContainerLaunchContext.html">ContainerLaunchContext</a> represents all of the information needed by the YARN NodeManager to launch a container.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p><a href="#ExecutorLauncher">ExecutorLauncher</a> is a custom <code>ApplicationMaster</code> for <a href="../spark-deploy-mode.adoc#client">client deploy mode</a> only for the purpose of easily distinguishing client and cluster deploy modes when using <code>ps</code> or <code>jps</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>$ jps -lm

71253 org.apache.spark.deploy.yarn.ExecutorLauncher --arg 192.168.99.1:50188 --properties-file /tmp/hadoop-jacek/nm-local-dir/usercache/jacek/appcache/.../__spark_conf__/__spark_conf__.properties</pre>
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>When <a href="#creating-instance">created</a> <code>ApplicationMaster</code> takes a <a href="#client">YarnRMClient</a> (to handle communication with <a href="spark-yarn-introduction.adoc#ResourceManager">YARN ResourceManager</a> for YARN containers for <code>ApplicationMaster</code> and executors).</p>
</div>
<div class="paragraph">
<p><code>ApplicationMaster</code> uses <a href="#allocator">YarnAllocator</a> to manage YARN containers with executors.</p>
</div>
<table id="internal-properties" class="tableblock frame-all grid-all stretch">
<caption class="title">Table 1. ApplicationMaster&#8217;s Internal Properties</caption>
<colgroup>
<col style="width: 25%;">
<col style="width: 25%;">
<col style="width: 50%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Name</th>
<th class="tableblock halign-left valign-top">Initial Value</th>
<th class="tableblock halign-left valign-top">Description</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="amEndpoint"></a> <code>amEndpoint</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(uninitialized)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="../spark-RpcEndpointRef.adoc">RpcEndpointRef</a> to the <strong>YarnAM</strong> RPC endpoint initialized when <code>ApplicationMaster</code> <a href="#runAMEndpoint">runAMEndpoint</a>.</p>
<p class="tableblock">CAUTION: FIXME When, in a Spark application&#8217;s lifecycle, does <code>runAMEndpoint</code> really happen?</p>
<p class="tableblock">Used exclusively when <code>ApplicationMaster</code> <a href="#addAmIpFilter">registers the web UI security filters</a> (in <a href="#isClusterMode"><code>client</code> deploy mode</a> when the driver runs outside <code>ApplicationMaster</code>).</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="sparkConf"></a> <code>sparkConf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">New <a href="../spark-SparkConf.adoc">SparkConf</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FIXME</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="finished"></a> <code>finished</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>false</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag to&#8230;&#8203;FIXME</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="yarnConf"></a> <code>yarnConf</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Hadoop&#8217;s <code>YarnConfiguration</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag to&#8230;&#8203;FIXME</p>
<p class="tableblock">Created using <a href="../spark-SparkHadoopUtil.adoc#newConfiguration">SparkHadoopUtil.newConfiguration</a></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="exitCode"></a> <code>exitCode</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>0</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FIXME</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="userClassThread"></a> <code>userClassThread</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(uninitialized)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FIXME</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="sparkContextPromise"></a> <code>sparkContextPromise</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>SparkContext</code> Scala&#8217;s <a href="http://www.scala-lang.org/api/current/scala/concurrent/Promise$.html">Promise</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Used only in <code>cluster</code> deploy mode (when the driver and <code>ApplicationMaster</code> run together in a YARN container) as a communication bus between <code>ApplicationMaster</code> and the separate <code>Driver</code> thread that <a href="#startUserApplication">runs a Spark application</a>.</p>
<p class="tableblock">Used to inform <code>ApplicationMaster</code> when a Spark application&#8217;s <code>SparkContext</code> has been initialized successfully or failed.</p>
<p class="tableblock">Non-<code>null</code> value <a href="#runDriver">allows <code>ApplicationMaster</code> to access the driver&#8217;s <code>RpcEnv</code></a> (available as <a href="#rpcEnv">rpcEnv</a>).</p>
<p class="tableblock">NOTE: A successful initialization of a Spark application&#8217;s <code>SparkContext</code> is when <a href="spark-yarn-yarnclusterscheduler.adoc#postStartHook">YARN-specific <code>TaskScheduler</code>, i.e. <code>YarnClusterScheduler</code>, gets informed that the Spark application has started</a>. <em>What a clever solution!</em></p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a id="rpcEnv"></a> <code>rpcEnv</code></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">(uninitialized)</p></td>
<td class="tableblock halign-left valign-top"><div class="content"><div class="paragraph">
<p><a href="spark-rpc.adoc">RpcEnv</a> which is:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>sparkYarnAM</code> RPC environment from <a href="#runExecutorLauncher-sparkYarnAM">a Spark application submitted to YARN in <code>client</code> deploy mode</a>.</p>
</li>
<li>
<p><code>sparkDriver</code> RPC environment from the <a href="#runDriver-rpcEnv">Spark application submitted to YARN in <code>cluster</code> deploy mode</a>.</p>
</li>
</ul>
</div></div></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#isClusterMode">isClusterMode</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock"><code>true</code> (when <a href="#command-line-parameters"><code>--class</code> was specified</a>)</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Flag&#8230;&#8203;FIXME</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock"><a href="#maxNumExecutorFailures">maxNumExecutorFailures</a></p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">FIXME</p></td>
<td class="tableblock halign-left valign-top"></td>
</tr>
</tbody>
</table>
<div class="sect2">
<h3 id="maxnumexecutorfailures-property"><a class="anchor" href="#maxnumexecutorfailures-property"></a><a class="link" href="#maxnumexecutorfailures-property"><a id="maxNumExecutorFailures"></a> <code>maxNumExecutorFailures</code> Property</a></h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Computed using the optional <a href="spark-yarn-settings.adoc#spark.yarn.max.executor.failures">spark.yarn.max.executor.failures</a> if set. Otherwise, it is twice <a href="../spark-Executor.adoc#spark.executor.instances">spark.executor.instances</a> or <a href="../spark-dynamic-allocation.adoc#spark.dynamicAllocation.maxExecutors">spark.dynamicAllocation.maxExecutors</a> (with dynamic allocation enabled) with the minimum of <code>3</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="creating-applicationmaster-instance"><a class="anchor" href="#creating-applicationmaster-instance"></a><a class="link" href="#creating-applicationmaster-instance"><a id="creating-instance"></a> Creating ApplicationMaster Instance</a></h3>
<div class="paragraph">
<p><code>ApplicationMaster</code> takes the following when created:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a id="args"></a> <a href="#ApplicationMasterArguments">ApplicationMasterArguments</a></p>
</li>
<li>
<p><a id="client"></a> <a href="spark-yarn-yarnrmclient.adoc">YarnRMClient</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p><code>ApplicationMaster</code> initializes the <a href="#internal-registries">internal registries and counters</a>.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Review the initialization again
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="reporterthread-method"><a class="anchor" href="#reporterthread-method"></a><a class="link" href="#reporterthread-method"><a id="reporterThread"></a> <code>reporterThread</code> Method</a></h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="launching-progress-reporter-threadlaunchreporterthread-method"><a class="anchor" href="#launching-progress-reporter-threadlaunchreporterthread-method"></a><a class="link" href="#launching-progress-reporter-threadlaunchreporterthread-method"><a id="launchReporterThread"></a> Launching Progress Reporter Thread&#8201;&#8212;&#8201;<code>launchReporterThread</code> Method</a></h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="setting-internal-sparkcontext-referencesparkcontextinitialized-method"><a class="anchor" href="#setting-internal-sparkcontext-referencesparkcontextinitialized-method"></a><a class="link" href="#setting-internal-sparkcontext-referencesparkcontextinitialized-method"><a id="sparkContextInitialized"></a> Setting Internal SparkContext Reference&#8201;&#8212;&#8201;<code>sparkContextInitialized</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">sparkContextInitialized(sc: SparkContext): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>sparkContextInitialized</code> passes the call on to the <code>ApplicationMaster.sparkContextInitialized</code> that sets the internal <code>sparkContextRef</code> reference (to be <code>sc</code>).</p>
</div>
</div>
<div class="sect2">
<h3 id="clearing-internal-sparkcontext-referencesparkcontextstopped-method"><a class="anchor" href="#clearing-internal-sparkcontext-referencesparkcontextstopped-method"></a><a class="link" href="#clearing-internal-sparkcontext-referencesparkcontextstopped-method"><a id="sparkContextStopped"></a> Clearing Internal SparkContext Reference&#8201;&#8212;&#8201;<code>sparkContextStopped</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">sparkContextStopped(sc: SparkContext): Boolean</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>sparkContextStopped</code> passes the call on to the <code>ApplicationMaster.sparkContextStopped</code> that clears the internal <code>sparkContextRef</code> reference (i.e. sets it to <code>null</code>).</p>
</div>
</div>
<div class="sect2">
<h3 id="registering-web-ui-security-filtersaddamipfilter-method"><a class="anchor" href="#registering-web-ui-security-filtersaddamipfilter-method"></a><a class="link" href="#registering-web-ui-security-filtersaddamipfilter-method"><a id="addAmIpFilter"></a> Registering web UI Security Filters&#8201;&#8212;&#8201;<code>addAmIpFilter</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">addAmIpFilter(): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>addAmIpFilter</code> is a helper method that &#8230;&#8203;???</p>
</div>
<div class="paragraph">
<p>It starts by reading Hadoop&#8217;s environmental variable <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/ApplicationConstants.html#APPLICATION_WEB_PROXY_BASE_ENV">ApplicationConstants.APPLICATION_WEB_PROXY_BASE_ENV</a> that it passes to <a href="spark-yarn-yarnrmclient.adoc#getAmIpFilterParams"><code>YarnRMClient</code> to compute the configuration for the <code>AmIpFilter</code> for web UI</a>.</p>
</div>
<div class="paragraph">
<p>In cluster deploy mode (when <code>ApplicationMaster</code> runs with web UI), it sets <code>spark.ui.filters</code> system property as <code>org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter</code>. It also sets system properties from the key-value configuration of <code>AmIpFilter</code> (computed earlier) as <code>spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.[key]</code> being <code>[value]</code>.</p>
</div>
<div class="paragraph">
<p>In client deploy mode (when <code>ApplicationMaster</code> runs on another JVM or even host than web UI), it simply sends a <code>AddWebUIFilter</code> to <code>ApplicationMaster</code> (namely to <a href="spark-yarn-AMEndpoint.adoc">AMEndpoint RPC Endpoint</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="finish-method"><a class="anchor" href="#finish-method"></a><a class="link" href="#finish-method"><a id="finish"></a> <code>finish</code> Method</a></h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="allocator-internal-reference-to-yarnallocator"><a class="anchor" href="#allocator-internal-reference-to-yarnallocator"></a><a class="link" href="#allocator-internal-reference-to-yarnallocator"><a id="allocator"></a> allocator Internal Reference to YarnAllocator</a></h3>
<div class="paragraph">
<p><code>allocator</code> is the internal reference to <a href="spark-yarn-YarnAllocator.adoc">YarnAllocator</a> that <code>ApplicationMaster</code> uses to request new or release outstanding containers for executors.</p>
</div>
<div class="paragraph">
<p><code>allocator</code> is <a href="spark-yarn-yarnrmclient.adoc#register">created</a> when <a href="#registerAM"><code>ApplicationMaster</code> is registered</a> (using the internal <a href="#client">YarnRMClient reference</a>).</p>
</div>
</div>
<div class="sect2">
<h3 id="launching-applicationmaster-standalone-applicationmain-method"><a class="anchor" href="#launching-applicationmaster-standalone-applicationmain-method"></a><a class="link" href="#launching-applicationmaster-standalone-applicationmain-method"><a id="main"></a> Launching ApplicationMaster Standalone Application&#8201;&#8212;&#8201;<code>main</code> Method</a></h3>
<div class="paragraph">
<p><code>ApplicationMaster</code> is started as a standalone application inside a YARN container on a node.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>ApplicationMaster</code> standalone application is launched as a result of <a href="spark-yarn-client.adoc#createContainerLaunchContext">sending a <code>ContainerLaunchContext</code> request</a> to launch <code>ApplicationMaster</code> for a Spark application to YARN ResourceManager.
</td>
</tr>
</table>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-yarn-ApplicationMaster-client-submitApplication.png" alt="spark yarn ApplicationMaster client submitApplication">
</div>
<div class="title">Figure 3. Submitting ApplicationMaster to YARN NodeManager</div>
</div>
<div class="paragraph">
<p>When executed, <code>main</code> first parses <a href="#command-line-parameters">command-line parameters</a> and then uses <a href="../spark-SparkHadoopUtil.adoc#runAsSparkUser">SparkHadoopUtil.runAsSparkUser</a> to run the main code with a Hadoop <code>UserGroupInformation</code> as a thread local variable (distributed to child threads) for authenticating HDFS and YARN calls.</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Enable <code>DEBUG</code> logging level for <code>org.apache.spark.deploy.SparkHadoopUtil</code> logger to see what happens inside.</p>
</div>
<div class="paragraph">
<p>Add the following line to <code>conf/log4j.properties</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>log4j.logger.org.apache.spark.deploy.SparkHadoopUtil=DEBUG</code></pre>
</div>
</div>
<div class="paragraph">
<p>Refer to <a href="../spark-logging.adoc">Logging</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You should see the following message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG running as user: [user]</code></pre>
</div>
</div>
<div class="paragraph">
<p><a href="../spark-SparkHadoopUtil.adoc#runAsSparkUser">SparkHadoopUtil.runAsSparkUser</a> function executes a block that <a href="#creating-instance">creates a <code>ApplicationMaster</code></a> (passing the <a href="#ApplicationMasterArguments">ApplicationMasterArguments</a> instance and a new <a href="spark-yarn-yarnrmclient.adoc">YarnRMClient</a>) and then <a href="#run">runs</a> it.</p>
</div>
</div>
<div class="sect2">
<h3 id="running-applicationmasterrun-method"><a class="anchor" href="#running-applicationmasterrun-method"></a><a class="link" href="#running-applicationmasterrun-method"><a id="run"></a> Running ApplicationMaster&#8201;&#8212;&#8201;<code>run</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">run(): Int</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>run</code> reads the <a href="#getAttemptId">application attempt id</a>.</p>
</div>
<div class="paragraph">
<p>(only <a href="#isClusterMode">in <code>cluster</code> deploy mode</a>) <code>run</code> sets <a href="#cluster-mode-settings"><code>cluster</code> deploy mode-specific settings</a> and sets the application attempt id (from YARN).</p>
</div>
<div class="paragraph">
<p><code>run</code> sets a <code>CallerContext</code> for <code>APPMASTER</code>.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Why is <code>CallerContext</code> required? It&#8217;s only executed when <code>hadoop.caller.context.enabled</code> is enabled and <code>org.apache.hadoop.ipc.CallerContext</code> class is on CLASSPATH.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO ApplicationAttemptId: [appAttemptId]</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>run</code> creates a Hadoop <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/fs/FileSystem.html">FileSystem</a> (using the internal <a href="#yarnConf">YarnConfiguration</a>).</p>
</div>
<div class="paragraph">
<p><code>run</code> registers the <a href="#shutdown-hook">cleanup shutdown hook</a>.</p>
</div>
<div class="paragraph">
<p><code>run</code> creates a <a href="../spark-security.adoc#SecurityManager">SecurityManager</a>.</p>
</div>
<div class="paragraph">
<p>(only when <a href="spark-yarn-settings.adoc#spark.yarn.credentials.file">spark.yarn.credentials.file</a> is defined) <code>run</code> <a href="spark-yarn-ConfigurableCredentialManager.adoc#creating-instance">creates a <code>ConfigurableCredentialManager</code></a> to <a href="spark-yarn-ConfigurableCredentialManager.adoc#credentialRenewer">get a <code>AMCredentialRenewer</code></a> and schedules login from keytab.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Security stuff begs for more details.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the end, <code>run</code> registers <code>ApplicationMaster</code> (with YARN ResourceManager) for the Spark application&#8201;&#8212;&#8201;either calling <a href="#runDriver">runDriver</a> (in <a href="#isClusterMode"><code>cluster</code> deploy mode</a>) or <a href="#runExecutorLauncher">runExecutorLauncher</a> (for <code>client</code> deploy mode).</p>
</div>
<div class="paragraph">
<p><code>run</code> exits with <a href="#exitCode"><code>0</code> exit code</a>.</p>
</div>
<div class="paragraph">
<p>In case of an exception, you should see the following ERROR message in the logs and <code>run</code> <a href="#finish">finishes</a> with <code>FAILED</code> final application status.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR Uncaught exception: [exception]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>run</code> is used exclusively when <code>ApplicationMaster</code> is <a href="#main">launched as a standalone application</a> (inside a YARN container on a YARN cluster).
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="creating-sparkyarnam-rpc-environment-and-registering-applicationmaster-with-yarn-resourcemanager-client-deploy-moderunexecutorlauncher-internal-method"><a class="anchor" href="#creating-sparkyarnam-rpc-environment-and-registering-applicationmaster-with-yarn-resourcemanager-client-deploy-moderunexecutorlauncher-internal-method"></a><a class="link" href="#creating-sparkyarnam-rpc-environment-and-registering-applicationmaster-with-yarn-resourcemanager-client-deploy-moderunexecutorlauncher-internal-method"><a id="runExecutorLauncher"></a> Creating sparkYarnAM RPC Environment and Registering ApplicationMaster with YARN ResourceManager (Client Deploy Mode)&#8201;&#8212;&#8201;<code>runExecutorLauncher</code> Internal Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">runExecutorLauncher(securityMgr: SecurityManager): Unit</code></pre>
</div>
</div>
<div id="runExecutorLauncher-sparkYarnAM" class="paragraph">
<p><code>runExecutorLauncher</code> <a href="../spark-rpc.adoc#create">creates <code>sparkYarnAM</code> RPC environment</a> (on <a href="spark-yarn-settings.adoc#spark.yarn.am.port">spark.yarn.am.port</a> port, the internal <a href="#sparkConf">SparkConf</a> and <code>clientMode</code> enabled).</p>
</div>
<div class="admonitionblock tip">
<table>
<tr>
<td class="icon">
<i class="fa icon-tip" title="Tip"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Read the note in <a href="../spark-rpc.adoc#create">Creating RpcEnv</a> to learn the meaning of <code>clientMode</code> input argument.</p>
</div>
<div class="paragraph">
<p><code>clientMode</code> is enabled for so-called a client-mode <code>ApplicationMaster</code> which is when a Spark application is submitted to YARN in <a href="../spark-deploy-mode.adoc#client"><code>client</code> deploy mode</a>.</p>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>runExecutorLauncher</code> then <a href="#waitForSparkDriver">waits until the driver accepts connections and creates <code>RpcEndpointRef</code> to communicate</a>.</p>
</div>
<div class="paragraph">
<p><code>runExecutorLauncher</code> <a href="#addAmIpFilter">registers web UI security filters</a>.</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Why is this needed? <code>addAmIpFilter</code>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the end, <code>runExecutorLauncher</code> <a href="#registerAM">registers <code>ApplicationMaster</code> with YARN ResourceManager and requests resources</a> and then pauses until <a href="#reporterThread">reporterThread</a> finishes.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runExecutorLauncher</code> is used exclusively when <a href="#run"><code>ApplicationMaster</code> is started</a> in <a href="#isClusterMode"><code>client</code> deploy mode</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="running-spark-applications-driver-and-registering-applicationmaster-with-yarn-resourcemanager-cluster-deploy-moderundriver-internal-method"><a class="anchor" href="#running-spark-applications-driver-and-registering-applicationmaster-with-yarn-resourcemanager-cluster-deploy-moderundriver-internal-method"></a><a class="link" href="#running-spark-applications-driver-and-registering-applicationmaster-with-yarn-resourcemanager-cluster-deploy-moderundriver-internal-method"><a id="runDriver"></a> Running Spark Application&#8217;s Driver and Registering ApplicationMaster with YARN ResourceManager (Cluster Deploy Mode)&#8201;&#8212;&#8201;<code>runDriver</code> Internal Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">runDriver(securityMgr: SecurityManager): Unit</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runDriver</code> starts a Spark application on a <a href="#userClassThread">separate thread</a>, registers <code>YarnAM</code> endpoint in the application&#8217;s <code>RpcEnv</code> followed by registering <code>ApplicationMaster</code> with YARN ResourceManager. In the end, <code>runDriver</code> waits for the Spark application to finish.</p>
</div>
<div class="paragraph">
<p>Internally, <code>runDriver</code> <a href="#addAmIpFilter">registers web UI security filters</a> and <a href="#startUserApplication">starts a Spark application</a> (on a <a href="#userClassThread">separate Thread</a>).</p>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Waiting for spark context initialization...</code></pre>
</div>
</div>
<div id="runDriver-rpcEnv" class="paragraph">
<p><code>runDriver</code> waits <a href="spark-yarn-settings.adoc#spark.yarn.am.waitTime">spark.yarn.am.waitTime</a> time till the Spark application&#8217;s <a href="../spark-SparkContext.adoc">SparkContext</a> is available and accesses the <a href="../spark-rpc.adoc">current <code>RpcEnv</code></a> (and saves it as the internal <a href="#rpcEnv">rpcEnv</a>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runDriver</code> uses <a href="../spark-SparkEnv.adoc#rpcEnv"><code>SparkEnv</code> to access the current <code>RpcEnv</code></a> that the <a href="../spark-SparkContext.adoc#env">Spark application&#8217;s <code>SparkContext</code> manages</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>runDriver</code> <a href="#runAMEndpoint">creates <code>RpcEndpointRef</code> to the driver&#8217;s <code>YarnScheduler</code> endpoint and registers <code>YarnAM</code> endpoint</a> (using <a href="../spark-driver.adoc#spark_driver_host">spark.driver.host</a> and <a href="../spark-driver.adoc#spark_driver_port">spark.driver.port</a> properties for the driver&#8217;s host and port and <code>isClusterMode</code> enabled).</p>
</div>
<div class="paragraph">
<p><code>runDriver</code> <a href="#registerAM">registers <code>ApplicationMaster</code> with YARN ResourceManager and requests cluster resources</a> (using the Spark application&#8217;s <a href="#rpcEnv">RpcEnv</a>, the driver&#8217;s RPC endpoint reference, <code>webUrl</code> if web UI is enabled and the input <code>securityMgr</code>).</p>
</div>
<div class="paragraph">
<p><code>runDriver</code> pauses until the Spark application finishes.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runDriver</code> uses Java&#8217;s <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html#join--">Thread.join</a> on the internal <a href="#userClassThread">Thread</a> reference to the Spark application running on it.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If the Spark application has not started in <a href="spark-yarn-settings.adoc#spark.yarn.am.waitTime">spark.yarn.am.waitTime</a> time, <code>runDriver</code> reports a <code>IllegalStateException</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>SparkContext is null but app is still running!</code></pre>
</div>
</div>
<div class="paragraph">
<p>If <code>TimeoutException</code> is reported while waiting for the Spark application to start, you should see the following ERROR message in the logs and <code>runDriver</code> <a href="#finish">finishes</a> with <code>FAILED</code> final application status and the error code <code>13</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR SparkContext did not initialize after waiting for [spark.yarn.am.waitTime] ms. Please check earlier log output for errors. Failing the application.</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runDriver</code> is used exclusively when <a href="#run"><code>ApplicationMaster</code> is started</a> in <a href="#isClusterMode"><code>cluster</code> deploy mode</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="starting-spark-application-in-separate-driver-threadstartuserapplication-method"><a class="anchor" href="#starting-spark-application-in-separate-driver-threadstartuserapplication-method"></a><a class="link" href="#starting-spark-application-in-separate-driver-threadstartuserapplication-method"><a id="startUserApplication"></a> Starting Spark Application (in Separate Driver Thread)&#8201;&#8212;&#8201;<code>startUserApplication</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">startUserApplication(): Thread</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> starts a Spark application as a separate <code>Driver</code> thread.</p>
</div>
<div class="paragraph">
<p>Internally, when <code>startUserApplication</code> is executed, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO Starting the user application in a separate Thread</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> takes the <a href="spark-yarn-client.adoc#getUserClasspath">user-specified jars</a> and maps them to use the <code>file:</code> protocol.</p>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> then creates a class loader to load the main class of the Spark application given the <a href="spark-yarn-client.adoc#isUserClassPathFirst">precedence of the Spark system jars and the user-specified jars</a>.</p>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> works on custom configurations for Python and R applications (which I don&#8217;t bother including here).</p>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> loads the main class (using the custom class loader created above with the user-specified jars) and creates a reference to the <code>main</code> method.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
The main class is specified as <code>userClass</code> in <a href="#ApplicationMasterArguments">ApplicationMasterArguments</a> when <a href="#creating-instance"><code>ApplicationMaster</code> was created</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>startUserApplication</code> starts a Java <a href="https://docs.oracle.com/javase/8/docs/api/java/lang/Thread.html">Thread</a> (with the name <strong>Driver</strong>) that invokes the <code>main</code> method (with the application arguments from <code>userArgs</code> from <a href="#ApplicationMasterArguments">ApplicationMasterArguments</a>). The <code>Driver</code> thread uses the internal <a href="#sparkContextPromise">sparkContextPromise</a> to <a href="#runDriver">notify <code>ApplicationMaster</code></a> about the execution status of the <code>main</code> method (success or failure).</p>
</div>
<div class="paragraph">
<p>When the main method (of the Spark application) finishes successfully, the <code>Driver</code> thread will <a href="#finish">finish</a> with <code>SUCCEEDED</code> final application status and code status <code>0</code> and you should see the following DEBUG message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>DEBUG Done running users class</code></pre>
</div>
</div>
<div class="paragraph">
<p>Any exceptions in the <code>Driver</code> thread are reported with corresponding ERROR message in the logs, <code>FAILED</code> final application status, appropriate code status.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>// SparkUserAppException
ERROR User application exited with status [exitCode]

// non-SparkUserAppException
ERROR User class threw exception: [cause]</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
A Spark application&#8217;s exit codes are passed directly to <a href="#finish">finish <code>ApplicationMaster</code></a> and recorded as <a href="#exitCode">exitCode</a> for future reference.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>startUserApplication</code> is used exclusively when <code>ApplicationMaster</code> <a href="#runDriver">runs a Spark application&#8217;s driver and registers itself with YARN ResourceManager</a> for <code>cluster</code> deploy mode.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="registering-applicationmaster-with-yarn-resourcemanager-and-requesting-yarn-cluster-resourcesregisteram-internal-method"><a class="anchor" href="#registering-applicationmaster-with-yarn-resourcemanager-and-requesting-yarn-cluster-resourcesregisteram-internal-method"></a><a class="link" href="#registering-applicationmaster-with-yarn-resourcemanager-and-requesting-yarn-cluster-resourcesregisteram-internal-method"><a id="registerAM"></a> Registering ApplicationMaster with YARN ResourceManager and Requesting YARN Cluster Resources&#8201;&#8212;&#8201;<code>registerAM</code> Internal Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">registerAM(
  _sparkConf: SparkConf,
  _rpcEnv: RpcEnv,
  driverRef: RpcEndpointRef,
  uiAddress: String,
  securityMgr: SecurityManager): Unit</code></pre>
</div>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-yarn-ApplicationMaster-registerAM.png" alt="spark yarn ApplicationMaster registerAM">
</div>
<div class="title">Figure 4. Registering ApplicationMaster with YARN ResourceManager</div>
</div>
<div class="paragraph">
<p>Internally, <code>registerAM</code> first takes the application and attempt ids, and creates the URL of <a href="../spark-history-server.adoc">Spark History Server</a> for the Spark application, i.e. <code>[address]/history/[appId]/[attemptId]</code>, by <a href="../spark-SparkHadoopUtil.adoc#substituteHadoopVariables">substituting Hadoop variables</a> (using the internal <a href="#yarnConf">YarnConfiguration</a>) in the optional <a href="spark-yarn-settings.adoc#spark.yarn.historyServer.address">spark.yarn.historyServer.address</a> setting.</p>
</div>
<div class="paragraph">
<p><code>registerAM</code> then creates a <a href="../spark-rpc.adoc#RpcEndpointAddress">RpcEndpointAddress</a> for the driver&#8217;s <a href="../spark-CoarseGrainedSchedulerBackend.adoc#CoarseGrainedScheduler">CoarseGrainedScheduler RPC endpoint</a> available at <a href="../spark-driver.adoc#spark.driver.host">spark.driver.host</a> and <a href="../spark-driver.adoc#spark.driver.port">spark.driver.port</a>.</p>
</div>
<div class="paragraph">
<p><code>registerAM</code> <a href="spark-yarn-ExecutorRunnable.adoc#launchContextDebugInfo">prints YARN launch context diagnostic information (with command, environment and resources) for executors</a> (with <a href="../spark-Executor.adoc#spark.executor.memory">spark.executor.memory</a>, <a href="../spark-Executor.adoc#spark.executor.cores">spark.executor.cores</a> and dummy <code>&lt;executorId&gt;</code> and <code>&lt;hostname&gt;</code>)</p>
</div>
<div class="paragraph">
<p><code>registerAM</code> requests <a href="spark-yarn-yarnrmclient.adoc#register"><code>YarnRMClient</code> to register <code>ApplicationMaster</code></a> (with YARN ResourceManager) and the internal <a href="#allocator">YarnAllocator</a> to <a href="spark-yarn-YarnAllocator.adoc#allocateResources">allocate required cluster resources</a> (given placement hints about where to allocate resource containers for executors to be as close to the data as possible).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>registerAM</code> uses <code>YarnRMClient</code> that was given when <a href="#creating-instance"><code>ApplicationManager</code> was created</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>In the end, <code>registerAM</code> <a href="#launchReporterThread">launches reporter thread</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>registerAM</code> is used when <code>ApplicationMaster</code> runs a Spark application in <a href="#runDriver"><code>cluster</code> deploy mode</a> and <a href="#runExecutorLauncher"><code>client</code> deploy mode</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="command-line-parametersapplicationmasterarguments-class"><a class="anchor" href="#command-line-parametersapplicationmasterarguments-class"></a><a class="link" href="#command-line-parametersapplicationmasterarguments-class"><a id="command-line-parameters"></a><a id="ApplicationMasterArguments"></a> Command-Line Parameters&#8201;&#8212;&#8201;<code>ApplicationMasterArguments</code> class</a></h3>
<div class="paragraph">
<p><code>ApplicationMaster</code> uses <code>ApplicationMasterArguments</code> class to handle command-line parameters.</p>
</div>
<div class="paragraph">
<p><code>ApplicationMasterArguments</code> is created right after <a href="#main">main</a> method has been executed for <code>args</code> command-line parameters.</p>
</div>
<div class="paragraph">
<p>It accepts the following command-line parameters:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><code>--jar JAR_PATH</code>&#8201;&#8212;&#8201;the path to the Spark application&#8217;s JAR file</p>
</li>
<li>
<p><code>--class CLASS_NAME</code>&#8201;&#8212;&#8201;the name of the Spark application&#8217;s main class</p>
</li>
<li>
<p><code>--arg ARG</code>&#8201;&#8212;&#8201;an argument to be passed to the Spark application&#8217;s main class. There can be multiple <code>--arg</code> arguments that are passed in order.</p>
</li>
<li>
<p><code>--properties-file FILE</code>&#8201;&#8212;&#8201;the path to a custom Spark properties file.</p>
</li>
<li>
<p><code>--primary-py-file FILE</code>&#8201;&#8212;&#8201;the main Python file to run.</p>
</li>
<li>
<p><code>--primary-r-file FILE</code>&#8201;&#8212;&#8201;the main R file to run.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>When an unsupported parameter is found the following message is printed out to standard error output and <code>ApplicationMaster</code> exits with the exit code <code>1</code>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Unknown/unsupported param [unknownParam]

Usage: org.apache.spark.deploy.yarn.ApplicationMaster [options]
Options:
  --jar JAR_PATH       Path to your application's JAR file
  --class CLASS_NAME   Name of your application's main class
  --primary-py-file    A main Python file
  --primary-r-file     A main R file
  --arg ARG            Argument to be passed to your application's main class.
                       Multiple invocations are possible, each will be passed in order.
  --properties-file FILE Path to a custom Spark properties file.</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="localresources-property"><a class="anchor" href="#localresources-property"></a><a class="link" href="#localresources-property"><a id="localResources"></a> <code>localResources</code> Property</a></h3>
<div class="paragraph">
<p>When <a href="#creating-instance"><code>ApplicationMaster</code> is instantiated</a>, it computes internal <code>localResources</code> collection of YARN&#8217;s <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResource.html">LocalResource</a> by name based on the internal <code>spark.yarn.cache.*</code> configuration settings.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">localResources: Map[String, LocalResource]</code></pre>
</div>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO ApplicationMaster: Preparing Local resources</code></pre>
</div>
</div>
<div class="paragraph">
<p>It starts by reading the internal Spark configuration settings (that were earlier set when <a href="spark-yarn-client.adoc#prepareLocalResources"><code>Client</code> prepared local resources to distribute</a>):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.cache.filenames">spark.yarn.cache.filenames</a></p>
</li>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.cache.sizes">spark.yarn.cache.sizes</a></p>
</li>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.cache.timestamps">spark.yarn.cache.timestamps</a></p>
</li>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.cache.visibilities">spark.yarn.cache.visibilities</a></p>
</li>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.cache.types">spark.yarn.cache.types</a></p>
</li>
</ul>
</div>
<div class="paragraph">
<p>For each file name in <a href="spark-yarn-settings.adoc#spark.yarn.cache.filenames">spark.yarn.cache.filenames</a> it maps <a href="spark-yarn-settings.adoc#spark.yarn.cache.types">spark.yarn.cache.types</a> to an appropriate YARN&#8217;s <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResourceType.html">LocalResourceType</a> and creates a new YARN <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResource.html">LocalResource</a>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResource.html">LocalResource</a> represents a local resource required to run a container.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>If <a href="spark-yarn-settings.adoc#spark.yarn.cache.confArchive">spark.yarn.cache.confArchive</a> is set, it is added to <code>localResources</code> as <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResourceType.html#ARCHIVE">ARCHIVE</a> resource type and <a href="https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/api/records/LocalResourceVisibility.html#PRIVATE">PRIVATE</a> visibility.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="spark-yarn-settings.adoc#spark.yarn.cache.confArchive">spark.yarn.cache.confArchive</a> is set when <a href="spark-yarn-client.adoc#prepareLocalResources"><code>Client</code> prepares local resources</a>.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>ARCHIVE</code> is an archive file that is automatically unarchived by the NodeManager.
</td>
</tr>
</table>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>PRIVATE</code> visibility means to share a resource among all applications of the same user on the node.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>Ultimately, it removes the cache-related settings from the <a href="../spark-SparkConf.adoc">Spark configuration</a> and system properties.</p>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO ApplicationMaster: Prepared Local resources [resources]</code></pre>
</div>
</div>
</div>
<div class="sect2">
<h3 id="cluster-mode-settings"><a class="anchor" href="#cluster-mode-settings"></a><a class="link" href="#cluster-mode-settings"><a id="cluster-mode-settings"></a> Cluster Mode Settings</a></h3>
<div class="paragraph">
<p>When in <a href="#isClusterMode"><code>cluster</code> deploy mode</a>, <code>ApplicationMaster</code> sets the following system properties (in <a href="#run">run</a>):</p>
</div>
<div class="ulist">
<ul>
<li>
<p><a href="../spark-webui-properties.adoc#spark.ui.port">spark.ui.port</a> to <code>0</code></p>
</li>
<li>
<p><a href="../spark-configuration-properties.adoc#spark.master">spark.master</a> as <code>yarn</code></p>
</li>
<li>
<p><a href="../spark-deploy-mode.adoc#spark.submit.deployMode">spark.submit.deployMode</a> as <code>cluster</code></p>
</li>
<li>
<p><a href="spark-yarn-settings.adoc#spark.yarn.app.id">spark.yarn.app.id</a> as YARN-specific application id</p>
</li>
</ul>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME Why are the system properties required? Who&#8217;s expecting them?
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="isclustermode-internal-flag"><a class="anchor" href="#isclustermode-internal-flag"></a><a class="link" href="#isclustermode-internal-flag"><a id="cluster-mode"></a><a id="isClusterMode"></a> <code>isClusterMode</code> Internal Flag</a></h3>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME <a href="spark-yarn-client.adoc#isClusterMode">Since <code>org.apache.spark.deploy.yarn.ExecutorLauncher</code> is used for client deploy mode</a>, the <code>isClusterMode</code> flag could be set there (not depending on <code>--class</code> which is correct yet not very obvious).
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>isClusterMode</code> is an internal flag that is enabled (i.e. <code>true</code>) for <a href="../spark-deploy-mode.adoc#cluster">cluster mode</a>.</p>
</div>
<div class="paragraph">
<p>Specifically, it says whether the main class of the Spark application (through <a href="#command-line-parameters"><code>--class</code> command-line argument</a>) was specified or not. That is how the developers decided to inform <code>ApplicationMaster</code> about being run in <a href="../spark-deploy-mode.adoc#cluster">cluster mode</a> when <a href="spark-yarn-client.adoc#createContainerLaunchContext"><code>Client</code> creates YARN&#8217;s <code>ContainerLaunchContext</code></a> (to launch the <code>ApplicationMaster</code> for a Spark application).</p>
</div>
<div class="paragraph">
<p><code>isClusterMode</code> is used to set <a href="#cluster-mode-settings">additional system properties</a> in <a href="#run">run</a> and <a href="#runDriver">runDriver</a> (the flag is enabled) or <a href="#runExecutorLauncher">runExecutorLauncher</a> (when disabled).</p>
</div>
<div class="paragraph">
<p>Besides, <code>isClusterMode</code> controls the <a href="#getDefaultFinalStatus">default final status of a Spark application</a> being <code>FinalApplicationStatus.FAILED</code> (when the flag is enabled) or <code>FinalApplicationStatus.UNDEFINED</code>.</p>
</div>
<div class="paragraph">
<p><code>isClusterMode</code> also controls whether to set system properties in <a href="#addAmIpFilter">addAmIpFilter</a> (when the flag is enabled) or <a href="#addAmIpFilter">send a <code>AddWebUIFilter</code> instead</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="unregistering-applicationmaster-from-yarn-resourcemanagerunregister-method"><a class="anchor" href="#unregistering-applicationmaster-from-yarn-resourcemanagerunregister-method"></a><a class="link" href="#unregistering-applicationmaster-from-yarn-resourcemanagerunregister-method"><a id="unregister"></a> Unregistering ApplicationMaster from YARN ResourceManager&#8201;&#8212;&#8201;<code>unregister</code> Method</a></h3>
<div class="paragraph">
<p><code>unregister</code> unregisters the <code>ApplicationMaster</code> for the Spark application from the <a href="spark-yarn-introduction.adoc#ResourceManager">YARN ResourceManager</a>.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">unregister(status: FinalApplicationStatus, diagnostics: String = null): Unit</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
It is called from the <a href="#shutdown-hook">cleanup shutdown hook</a> (that was registered in <code>ApplicationMaster</code> when it <a href="#run">started running</a>) and only when the application&#8217;s final result is successful or it was the last attempt to run the application.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>It first checks that the <code>ApplicationMaster</code> has not already been unregistered (using the internal <code>unregistered</code> flag). If so, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO ApplicationMaster: Unregistering ApplicationMaster with [status]</code></pre>
</div>
</div>
<div class="paragraph">
<p>There can also be an optional diagnostic message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>(diag message: [msg])</code></pre>
</div>
</div>
<div class="paragraph">
<p>The internal <code>unregistered</code> flag is set to be enabled, i.e. <code>true</code>.</p>
</div>
<div class="paragraph">
<p>It then requests <a href="spark-yarn-yarnrmclient.adoc#unregister"><code>YarnRMClient</code> to unregister</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="cleanup-shutdown-hook"><a class="anchor" href="#cleanup-shutdown-hook"></a><a class="link" href="#cleanup-shutdown-hook"><a id="shutdown-hook"></a> Cleanup Shutdown Hook</a></h3>
<div class="paragraph">
<p>When <a href="#run"><code>ApplicationMaster</code> starts running</a>, it registers a shutdown hook that <a href="#unregister">unregisters the Spark application from the YARN ResourceManager</a> and <a href="#cleanupStagingDir">cleans up the staging directory</a>.</p>
</div>
<div class="paragraph">
<p>Internally, it checks the internal <code>finished</code> flag, and if it is disabled, it <a href="#finish">marks the Spark application as failed with <code>EXIT_EARLY</code></a>.</p>
</div>
<div class="paragraph">
<p>If the internal <code>unregistered</code> flag is disabled, it <a href="#unregister">unregisters the Spark application</a> and <a href="#cleanupStagingDir">cleans up the staging directory</a> afterwards only when the final status of the ApplicationMaster&#8217;s registration is <code>FinalApplicationStatus.SUCCEEDED</code> or the <a href="README.adoc#multiple-application-attempts">number of application attempts is more than allowed</a>.</p>
</div>
<div class="paragraph">
<p>The shutdown hook runs after the SparkContext is shut down, i.e. the shutdown priority is one less than SparkContext&#8217;s.</p>
</div>
<div class="paragraph">
<p>The shutdown hook is registered using Spark&#8217;s own <code>ShutdownHookManager.addShutdownHook</code>.</p>
</div>
</div>
<div class="sect2">
<h3 id="executorlauncher"><a class="anchor" href="#executorlauncher"></a><a class="link" href="#executorlauncher"><a id="ExecutorLauncher"></a> ExecutorLauncher</a></h3>
<div class="paragraph">
<p><code>ExecutorLauncher</code> comes with no extra functionality when compared to <code>ApplicationMaster</code>. It serves as a helper class to run <code>ApplicationMaster</code> under another class name in <a href="spark-deploy-mode.adoc#client">client deploy mode</a>.</p>
</div>
<div class="paragraph">
<p>With the two different class names (pointing at the same class <code>ApplicationMaster</code>) you should be more successful to distinguish between <code>ExecutorLauncher</code> (which is really a <code>ApplicationMaster</code>) in <a href="spark-deploy-mode.adoc#client">client deploy mode</a> and the <code>ApplicationMaster</code> in <a href="spark-deploy-mode.adoc#cluster">cluster deploy mode</a> using tools like <code>ps</code> or <code>jps</code>.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
Consider <code>ExecutorLauncher</code> a <code>ApplicationMaster</code> for client deploy mode.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="obtain-application-attempt-idgetattemptid-method"><a class="anchor" href="#obtain-application-attempt-idgetattemptid-method"></a><a class="link" href="#obtain-application-attempt-idgetattemptid-method"><a id="getAttemptId"></a> Obtain Application Attempt Id&#8201;&#8212;&#8201;<code>getAttemptId</code> Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">getAttemptId(): ApplicationAttemptId</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>getAttemptId</code> returns YARN&#8217;s <code>ApplicationAttemptId</code> (of the Spark application to which the container was assigned).</p>
</div>
<div class="paragraph">
<p>Internally, it queries YARN by means of <a href="spark-yarn-yarnrmclient.adoc#getAttemptId">YarnRMClient</a>.</p>
</div>
</div>
<div class="sect2">
<h3 id="waiting-until-driver-is-network-accessible-and-creating-rpcendpointref-to-communicatewaitforsparkdriver-internal-method"><a class="anchor" href="#waiting-until-driver-is-network-accessible-and-creating-rpcendpointref-to-communicatewaitforsparkdriver-internal-method"></a><a class="link" href="#waiting-until-driver-is-network-accessible-and-creating-rpcendpointref-to-communicatewaitforsparkdriver-internal-method"><a id="waitForSparkDriver"></a> Waiting Until Driver is Network-Accessible and Creating RpcEndpointRef to Communicate&#8201;&#8212;&#8201;<code>waitForSparkDriver</code> Internal Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">waitForSparkDriver(): RpcEndpointRef</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>waitForSparkDriver</code> waits until the driver is network-accessible, i.e. accepts connections on a given host and port, and returns a <code>RpcEndpointRef</code> to the driver.</p>
</div>
<div class="paragraph">
<p>When executed, you should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO yarn.ApplicationMaster: Waiting for Spark driver to be reachable.</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>waitForSparkDriver</code> takes the driver&#8217;s host and port (using <a href="#ApplicationMasterArguments">ApplicationMasterArguments</a> passed in when <a href="#creating-instance"><code>ApplicationMaster</code> was created</a>).</p>
</div>
<div class="admonitionblock caution">
<table>
<tr>
<td class="icon">
<i class="fa icon-caution" title="Caution"></i>
</td>
<td class="content">
FIXME <code>waitForSparkDriver</code> expects the driver&#8217;s host and port as the 0-th element in <code>ApplicationMasterArguments.userArgs</code>. Why?
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>waitForSparkDriver</code> tries to connect to the driver&#8217;s host and port until the driver accepts the connection but no longer than <a href="spark-yarn-settings.adoc#spark.yarn.am.waitTime">spark.yarn.am.waitTime</a> setting or <a href="#finished">finished</a> internal flag is enabled.</p>
</div>
<div class="paragraph">
<p>You should see the following INFO message in the logs:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>INFO yarn.ApplicationMaster: Driver now available: [driverHost]:[driverPort]</code></pre>
</div>
</div>
<div class="paragraph">
<p>While <code>waitForSparkDriver</code> tries to connect (while the socket is down), you can see the following ERROR message and <code>waitForSparkDriver</code> pauses for 100 ms and tries to connect again (until the <code>waitTime</code> elapses).</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>ERROR Failed to connect to driver at [driverHost]:[driverPort], retrying ...</code></pre>
</div>
</div>
<div class="paragraph">
<p>Once <code>waitForSparkDriver</code> could connect to the driver, <code>waitForSparkDriver</code> sets <a href="../spark-driver.adoc#spark.driver.host">spark.driver.host</a> and <a href="../spark-driver.adoc#spark.driver.port">spark.driver.port</a> properties to <code>driverHost</code> and <code>driverPort</code>, respectively (using the internal <a href="#sparkConf">SparkConf</a>).</p>
</div>
<div class="paragraph">
<p>In the end, <code>waitForSparkDriver</code> <a href="#runAMEndpoint">runAMEndpoint</a>.</p>
</div>
<div class="paragraph">
<p>If <code>waitForSparkDriver</code> did not manage to connect (before <code>waitTime</code> elapses or <a href="#finished">finished</a> internal flag was enabled), <code>waitForSparkDriver</code> reports a <code>SparkException</code>:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code>Failed to connect to driver!</code></pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>waitForSparkDriver</code> is used exclusively when client-mode <code>ApplicationMaster</code> <a href="#runExecutorLauncher">creates the <code>sparkYarnAM</code> RPC environment and registers itself with YARN ResourceManager</a>.
</td>
</tr>
</table>
</div>
</div>
<div class="sect2">
<h3 id="creating-rpcendpointref-to-drivers-yarnscheduler-endpoint-and-registering-yarnam-endpointrunamendpoint-internal-method"><a class="anchor" href="#creating-rpcendpointref-to-drivers-yarnscheduler-endpoint-and-registering-yarnam-endpointrunamendpoint-internal-method"></a><a class="link" href="#creating-rpcendpointref-to-drivers-yarnscheduler-endpoint-and-registering-yarnam-endpointrunamendpoint-internal-method"><a id="runAMEndpoint"></a> Creating RpcEndpointRef to Driver&#8217;s YarnScheduler Endpoint and Registering YarnAM Endpoint&#8201;&#8212;&#8201;<code>runAMEndpoint</code> Internal Method</a></h3>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-scala hljs" data-lang="scala">runAMEndpoint(host: String, port: String, isClusterMode: Boolean): RpcEndpointRef</code></pre>
</div>
</div>
<div class="paragraph">
<p><code>runAMEndpoint</code> sets up a <a href="../spark-RpcEndpointRef.adoc">RpcEndpointRef</a> to the driver&#8217;s <code>YarnScheduler</code> endpoint and registers <strong>YarnAM</strong> endpoint.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>sparkDriver</code> RPC environment when the driver lives in YARN cluster (in <code>cluster</code> deploy mode)
</td>
</tr>
</table>
</div>
<div class="imageblock text-center">
<div class="content">
<img src="_images/spark-yarn-ApplicationMaster-runAMEndpoint.png" alt="spark yarn ApplicationMaster runAMEndpoint">
</div>
<div class="title">Figure 5. Registering YarnAM Endpoint</div>
</div>
<div class="paragraph">
<p>Internally, <code>runAMEndpoint</code> <a href="../spark-rpc.adoc#setupEndpointRefByURI">gets a <code>RpcEndpointRef</code></a> to the driver&#8217;s <code>YarnScheduler</code> endpoint (available on the <code>host</code> and <code>port</code>).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>YarnScheduler</code> RPC endpoint is registered when the <a href="spark-yarn-yarnschedulerbackend.adoc#creating-instance">Spark coarse-grained scheduler backends for YARN are created</a>.
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p><code>runAMEndpoint</code> then <a href="../spark-rpc.adoc#setupEndpoint">registers the RPC endpoint</a> as <strong>YarnAM</strong> (and <a href="spark-yarn-AMEndpoint.adoc">AMEndpoint</a> implementation with <code>ApplicationMaster</code>'s <a href="#rpcEnv">RpcEnv</a>, <code>YarnScheduler</code> endpoint reference, and <code>isClusterMode</code> flag).</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<code>runAMEndpoint</code> is used when <code>ApplicationMaster</code> <a href="#waitForSparkDriver">waits for the driver</a> (in client deploy mode) and <a href="#runDriver">runs the driver</a> (in cluster deploy mode).
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
</article>
</main>
</div>
<footer class="footer">
  <p>This page was built using the Antora default UI.</p>
  <p>The source code for this UI is licensed under the terms of the MPL-2.0 license.</p>
</footer>
<script src="../../../_/js/site.js"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
